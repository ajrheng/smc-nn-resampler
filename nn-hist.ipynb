{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed = 10000\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "generate_data = False\n",
    "load = True\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # encoder\n",
    "        self.enc1 = nn.Linear(n_input,50)\n",
    "        self.enc2 = nn.Linear(50,25)\n",
    "        self.enc3 = nn.Linear(25,10)\n",
    "        \n",
    "        # decoder\n",
    "        self.dec1 = nn.Linear(10, 25)\n",
    "        self.dec2 = nn.Linear(25, 50)\n",
    "        self.dec3 = nn.Linear(50, n_output)\n",
    "        \n",
    "        #bn\n",
    "        self.bn_enc1 = nn.BatchNorm1d(50)\n",
    "        self.bn_enc2 = nn.BatchNorm1d(25)\n",
    "        self.bn_enc3 = nn.BatchNorm1d(10)\n",
    "        self.bn_dec1 = nn.BatchNorm1d(25)\n",
    "        self.bn_dec2 = nn.BatchNorm1d(50)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn_enc1(torch.relu(self.enc1(x)))\n",
    "        x = self.bn_enc2(torch.relu(self.enc2(x)))\n",
    "        x = self.bn_enc3(torch.relu(self.enc3(x)))\n",
    "        x = self.bn_dec1(torch.relu(self.dec1(x)))\n",
    "        x = self.bn_dec2(torch.relu(self.dec2(x)))\n",
    "        x = F.softmax(self.dec3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_samples_per_mode(num_modes, total_points):\n",
    "    \"\"\"\n",
    "    Returns the number of points to sample for each number of mode.\n",
    "    \n",
    "    Args:\n",
    "        num_modes: number of different modes in the multimodal distribution\n",
    "        total_points: total number of points to draw for all modes\n",
    "        \n",
    "    Returns:\n",
    "        array with the number of samples per mode. the elements sum to total_points\n",
    "    \"\"\"\n",
    "    prob_per_mode = np.random.dirichlet(np.ones(num_modes))\n",
    "    num_samples = []\n",
    "    \n",
    "    for i in range(num_modes):\n",
    "        \n",
    "        if i == num_modes - 1: # if the last mode:\n",
    "            num = total_points - sum(num_samples)\n",
    "        else:\n",
    "            num = int(prob_per_mode[i] * total_points)\n",
    "            \n",
    "        num_samples.append(num)\n",
    "        \n",
    "    return np.array(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_binned_gaussian(num_data, num_samples, num_bins, num_modes):\n",
    "    \"\"\"\n",
    "    Returns (binned_data, binned_edges)\n",
    "    binned_data contains the binned training data, has dimensions [num_data, num_bins]\n",
    "    binned_edges contains the binned edges, has dimensions [num_data, num_bins+1]\n",
    "    \n",
    "    Args:\n",
    "        num_data: number of data points (full batch size)\n",
    "        num_samples: number of samples/particles to draw\n",
    "        num_bins: number of bins\n",
    "        num_modes: number of modes you want in the data. each data\n",
    "                   point will have a random number of modes from 1 to num_modes\n",
    "    \"\"\"\n",
    "    \n",
    "    binned_data = np.empty((0, num_bins), float)\n",
    "    edges = np.empty((0, num_bins+1), float)\n",
    "    \n",
    "    for i in tqdm(range(num_data)):\n",
    "        num_mode = np.random.randint(low=1, high=num_modes)\n",
    "        num_samples_list = num_samples_per_mode(num_mode, num_samples)\n",
    "        \n",
    "        points = np.empty(shape=0)\n",
    "        \n",
    "        for n_samples in num_samples_list:\n",
    "            mean = np.random.uniform(-10,10)\n",
    "            std = np.random.uniform(1,1.5)\n",
    "            points_ = np.random.normal(loc=mean, scale=std, size=n_samples)\n",
    "            points = np.append(points, points_)\n",
    "            \n",
    "        ## normalize\n",
    "        points =  (points - np.mean(points))/np.std(points)\n",
    "        bins_, edges_ = np.histogram(points, bins=num_bins)\n",
    "        bins_ = bins_/num_samples\n",
    "        \n",
    "        binned_data = np.append(binned_data, [bins_], axis=0)\n",
    "        edges = np.append(edges, [edges_], axis=0)\n",
    "        \n",
    "    return binned_data, edges\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_num_data = 50000\n",
    "test_num_data = 5000\n",
    "num_samples = 10000\n",
    "num_bins = 100\n",
    "num_modes = 10\n",
    "\n",
    "if generate_data is True:\n",
    "    train_data, train_edges = draw_binned_gaussian(train_num_data, num_samples, num_bins, num_modes)\n",
    "    test_data, test_edges = draw_binned_gaussian(test_num_data, num_samples, num_bins, num_modes)\n",
    "    np.save(\"train_data.npy\", train_data)\n",
    "    np.save(\"train_edges.npy\", train_edges)\n",
    "    np.save(\"test_data.npy\", test_data)\n",
    "    np.save(\"test_edges.npy\", test_edges)\n",
    "else:\n",
    "    train_data = np.load(\"train_data.npy\")\n",
    "    train_edges = np.load(\"train_edges.npy\")\n",
    "    test_data = np.load(\"test_data.npy\")\n",
    "    test_edges = np.load(\"test_edges.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.astype(np.float32)\n",
    "train_data = torch.from_numpy(train_data)\n",
    "train_data = train_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.astype(np.float32)\n",
    "test_data = torch.from_numpy(test_data)\n",
    "test_data = test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (enc1): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (enc2): Linear(in_features=50, out_features=25, bias=True)\n",
       "  (enc3): Linear(in_features=25, out_features=10, bias=True)\n",
       "  (dec1): Linear(in_features=10, out_features=25, bias=True)\n",
       "  (dec2): Linear(in_features=25, out_features=50, bias=True)\n",
       "  (dec3): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (bn_enc1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn_enc2): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn_enc3): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn_dec1): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn_dec2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 30000\n",
    "net = Net(100,100)\n",
    "net = net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_func = nn.KLDivLoss()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_est_data = np.load(\"train_data.npy\")\n",
    "phase_est_data = phase_est_data.astype(np.float32)\n",
    "phase_est_data = torch.from_numpy(phase_est_data)\n",
    "phase_est_data = phase_est_data.to(device)\n",
    "\n",
    "phase_est_edges = np.load(\"train_edges.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (enc1): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (enc2): Linear(in_features=50, out_features=25, bias=True)\n",
       "  (enc3): Linear(in_features=25, out_features=10, bias=True)\n",
       "  (dec1): Linear(in_features=10, out_features=25, bias=True)\n",
       "  (dec2): Linear(in_features=25, out_features=50, bias=True)\n",
       "  (dec3): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (bn_enc1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn_enc2): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn_enc3): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn_dec1): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn_dec2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if load is False:\n",
    "    for e in range(epochs):\n",
    "        prediction = net(train_data)\n",
    "        loss = loss_func(torch.log(prediction), train_data)\n",
    "        train_loss = loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (e+1)%250 == 0:\n",
    "            net.eval()\n",
    "            test_pred = net(test_data)\n",
    "            loss = loss_func(torch.log(test_pred), test_data)\n",
    "            test_loss = loss.item()\n",
    "\n",
    "            phase_est_pred = net(phase_est_data)\n",
    "            loss = loss_func(torch.log(phase_est_pred), phase_est_data)\n",
    "            phase_est_loss = loss.item()\n",
    "\n",
    "            print(\"Epoch: {:d}, train loss: {:f}, test loss: {:f}, phase est loss: {:f}\"\n",
    "                  .format(e, train_loss, test_loss, phase_est_loss))\n",
    "            net.train()\n",
    "\n",
    "    torch.save(net.state_dict(), \"net_bn_aft_relu_dropout.model\")\n",
    "else:\n",
    "    net.load_state_dict(torch.load(\"net_bn_aft_relu.model\"))\n",
    "\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4475 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-6eba39833492>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_edges_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'edge'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medge_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_edges_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'edge'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medge_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 4475 is out of bounds for dimension 0 with size 1"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_pred = net(test_data)\n",
    "idx_to_plot = np.random.choice(test_num_data, size=100)\n",
    "\n",
    "for i in idx_to_plot:\n",
    "    \n",
    "    test_edges_ = test_edges[i][:-1]\n",
    "    edge_width = test_edges_[1] - test_edges_[0]\n",
    "\n",
    "    plt.bar(test_edges_, test_data[i].cpu(), align='edge', width = edge_width)\n",
    "    plt.bar(test_edges_, test_pred[i].detach().cpu(), align='edge', width = edge_width, alpha=0.7)\n",
    "    plt.show() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phase_est_pred = net(phase_est_data)\n",
    "idx_to_plot = np.random.choice(len(phase_est_data), size=100)\n",
    "\n",
    "for i in idx_to_plot:\n",
    "    \n",
    "    phase_est_edges_ = phase_est_edges[i][:-1]\n",
    "    edge_width = phase_est_edges_[1] - phase_est_edges_[0]\n",
    "\n",
    "    plt.bar(phase_est_edges_, phase_est_data[i].cpu(), align='edge', width = edge_width)\n",
    "    plt.bar(phase_est_edges_, phase_est_pred[i].detach().cpu(), align='edge', width = edge_width, alpha=0.7)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
